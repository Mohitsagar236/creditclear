{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc8257e",
   "metadata": {},
   "source": [
    "# Credit Risk Model - Model Training and Evaluation\n",
    "\n",
    "This notebook demonstrates the training and evaluation of our credit risk model using LightGBM and MLflow for experiment tracking.\n",
    "\n",
    "## Process Overview\n",
    "1. Data loading and preparation\n",
    "2. Model configuration and training\n",
    "3. Model evaluation using ROC AUC\n",
    "4. Experiment tracking with MLflow\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec2654",
   "metadata": {},
   "source": [
    "## Prerequisites Check\n",
    "\n",
    "Let's verify all required dependencies and data files are available before proceeding with the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18199ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import our custom model\n",
    "from src.models.lightgbm_model import LightGBMModel\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Set up MLflow experiment\n",
    "EXPERIMENT_NAME = \"Credit_Risk_Baseline\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Set up data paths\n",
    "DATA_DIR = Path('../data/processed')\n",
    "TRAIN_PATH = DATA_DIR / 'application_train_processed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6b08",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load the processed training data and prepare it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57482f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed training data\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb70e04",
   "metadata": {},
   "source": [
    "## Model Training with MLflow Tracking\n",
    "\n",
    "Train the LightGBM model and track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"lightgbm_baseline\"):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = LightGBMModel(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"roc_auc_score\", roc_auc)\n",
    "    \n",
    "    # Log feature importance\n",
    "    feature_importance = model.get_feature_importance(importance_type='gain')\n",
    "    \n",
    "    # Convert feature importance to a format suitable for MLflow\n",
    "    for feature, importance in feature_importance.items():\n",
    "        mlflow.log_metric(f\"feature_importance_{feature}\", importance)\n",
    "    \n",
    "    # SHAP Explainability Analysis\n",
    "    print(\"Generating SHAP explanations...\")\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.TreeExplainer(model.model)\n",
    "    \n",
    "    # Calculate SHAP values for validation set (sample subset for performance)\n",
    "    # Use a sample of validation data for SHAP to improve performance\n",
    "    sample_size = min(1000, len(X_val))\n",
    "    X_val_sample = X_val.sample(n=sample_size, random_state=RANDOM_STATE)\n",
    "    \n",
    "    shap_values = explainer.shap_values(X_val_sample)\n",
    "    \n",
    "    # Generate SHAP summary bar plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(shap_values, X_val_sample, plot_type=\"bar\", show=False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    shap_plot_path = \"shap_summary.png\"\n",
    "    plt.savefig(shap_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Log the SHAP plot as MLflow artifact\n",
    "    mlflow.log_artifact(shap_plot_path)\n",
    "    \n",
    "    # Also create and log a SHAP waterfall plot for a single prediction\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.waterfall_plot(explainer.expected_value, shap_values[0], X_val_sample.iloc[0], show=False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    waterfall_plot_path = \"shap_waterfall.png\"\n",
    "    plt.savefig(waterfall_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Log the waterfall plot as well\n",
    "    mlflow.log_artifact(waterfall_plot_path)\n",
    "    \n",
    "    # Log SHAP statistics\n",
    "    mlflow.log_metric(\"shap_mean_abs_value\", np.mean(np.abs(shap_values)))\n",
    "    mlflow.log_metric(\"shap_sample_size\", sample_size)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.lightgbm.log_model(\n",
    "        model.model,\n",
    "        \"model\",\n",
    "        registered_model_name=\"credit_risk_lightgbm\"\n",
    "    )\n",
    "    \n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "    print(f\"SHAP values calculated for {sample_size} samples\")\n",
    "    \n",
    "    # Display top 10 most important features\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_importance.keys(),\n",
    "        'importance': feature_importance.values()\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    display(importance_df.head(10))\n",
    "    \n",
    "    # Display SHAP feature importance (mean absolute SHAP values)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': X_val_sample.columns,\n",
    "        'mean_abs_shap_value': np.mean(np.abs(shap_values), axis=0)\n",
    "    }).sort_values('mean_abs_shap_value', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features by SHAP Importance:\")\n",
    "    display(shap_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68180cd4",
   "metadata": {},
   "source": [
    "## Model Artifacts and Results\n",
    "\n",
    "The trained model and its metrics are now tracked in MLflow. You can access them using the MLflow UI or programmatically.\n",
    "\n",
    "To view the MLflow UI, run:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "The logged artifacts include:\n",
    "- Model hyperparameters\n",
    "- ROC AUC score\n",
    "- Feature importance scores\n",
    "- Trained model (can be loaded for predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load the saved model from MLflow\n",
    "loaded_model = mlflow.lightgbm.load_model(\"runs:/[RUN_ID]/model\")\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Verify the predictions are the same as before\n",
    "print(f\"Predictions match: {np.allclose(predictions, y_pred_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def check_package_version(package_name):\n",
    "    try:\n",
    "        package = __import__(package_name)\n",
    "        version = getattr(package, '__version__', 'unknown')\n",
    "        return f\"✓ {package_name} (version {version})\"\n",
    "    except ImportError:\n",
    "        return f\"✗ {package_name} is not installed\"\n",
    "\n",
    "# Check required packages\n",
    "required_packages = [\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'scikit-learn',\n",
    "    'lightgbm',\n",
    "    'mlflow',\n",
    "    'shap',\n",
    "    'matplotlib'\n",
    "]\n",
    "\n",
    "print(\"Checking required packages:\")\n",
    "for package in required_packages:\n",
    "    print(check_package_version(package))\n",
    "\n",
    "# Check Python version\n",
    "print(f\"\\nPython version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check if data file exists\n",
    "data_path = Path('../data/processed/application_train_processed.csv')\n",
    "print(f\"\\nChecking data file:\")\n",
    "print(f\"{'✓' if data_path.exists() else '✗'} {data_path} \"\n",
    "      f\"({'exists' if data_path.exists() else 'does not exist'})\")\n",
    "\n",
    "# If any package is missing, show installation command\n",
    "missing_packages = [pkg for pkg in required_packages \n",
    "                   if not check_package_version(pkg).startswith('✓')]\n",
    "\n",
    "if missing_packages:\n",
    "    print(\"\\nTo install missing packages, run:\")\n",
    "    print(f\"pip install {' '.join(missing_packages)}\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(\"\\nWarning: Training data file not found!\")\n",
    "    print(\"Please ensure the processed data file is available at:\")\n",
    "    print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a40c9",
   "metadata": {},
   "source": [
    "## MLflow Setup Verification\n",
    "\n",
    "Let's verify MLflow is properly configured and we can create experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Test MLflow setup\n",
    "print(\"Testing MLflow setup:\")\n",
    "\n",
    "try:\n",
    "    # Get MLflow tracking URI\n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    print(f\"✓ MLflow tracking URI: {tracking_uri}\")\n",
    "    \n",
    "    # Test experiment creation\n",
    "    experiment_name = \"test_experiment\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(f\"✓ Successfully created test experiment: {experiment_name}\")\n",
    "    \n",
    "    # Test run creation\n",
    "    with mlflow.start_run(run_name=\"test_run\"):\n",
    "        mlflow.log_param(\"test_param\", \"test_value\")\n",
    "        print(\"✓ Successfully created test run and logged parameter\")\n",
    "        \n",
    "    print(\"\\nMLflow is properly configured!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ MLflow setup error: {str(e)}\")\n",
    "    print(\"\\nTo configure MLflow:\")\n",
    "    print(\"1. Ensure MLflow is installed: pip install mlflow\")\n",
    "    print(\"2. Set MLFLOW_TRACKING_URI environment variable if using remote tracking server\")\n",
    "    print(\"3. Ensure you have write permissions in the local directory for MLflow files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb9e67",
   "metadata": {},
   "source": [
    "## SHAP (SHapley Additive exPlanations) Analysis\n",
    "\n",
    "SHAP provides model explainability by calculating the contribution of each feature to individual predictions. The analysis includes:\n",
    "\n",
    "1. **SHAP Summary Bar Plot**: Shows the mean absolute SHAP values for each feature, indicating their overall importance\n",
    "2. **SHAP Waterfall Plot**: Demonstrates how each feature contributes to a single prediction\n",
    "3. **Feature Importance Comparison**: Compares traditional feature importance with SHAP-based importance\n",
    "\n",
    "The SHAP plots are saved as artifacts in MLflow for future reference and model documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
